\documentclass[inz, english, longabstract]{iithesis}
%
% \usepackage[utf8]{inputenc} 
%
\polishtitle    {Implementacja statycznej i dynamicznej semantyki rachunku z efektami algebraicznymi i ich obsługą z pomocą biblioteki \Redex}
\englishtitle   {Implementation of static and~dynamic semantics for a calculus with algebraic effects and~handlers using \Redex}
\polishabstract {%
Efekty algebraiczne są coraz popularniejszą techniką strukturyzowania efektów obliczeniowych.
Pozwalają one na rozdzielenie interfejsu pewnego obliczenia w postaci zbioru dozwolonych operacji, od jego implementacji w postaci wyrażeń obsługujących wywołania tych operacji.
W literaturze przedstawionych jest wiele rachunków oraz języków które mierzą się z efektami algebraicznymi, jednak są one na ogół albo mocno wyspecjalizowane i opisane ciężkim formalizmem, lub rozwijane w kierunku pełnego języka programowania, co wiąże się z komplikacją ich meta-teorii oraz implementacji.
W niniejszej pracy zdecydowałem się zbudować rachunek, który jest na tyle mały by nie przytłaczać użytkownika, lecz wciąż posiada wystarczający zasób konstrukcji ogólnego użytku do zbudowania kompletnych programów pozwalających na eksperymentalne poznawanie efektów algebraicznych.
Na poziomie teoretycznym stworzyłem system typów w stylu Curry'ego, relację redukcji dla termów rachunku oraz maszynę abstrakcyjną.
Rachunek został zaimplementowany z pomocą biblioteki \Redex{} i udostępnia programiście operacje i wyrażenia je obsługujące, funkcje rekurencyjne, wyrażenia liczbowe, logiczne, listy oraz wyrażenia warunkowe.
System typów został zbudowany tak, aby algorytmicznie odtwarzał typ wyrażenia, a relacja redukcji oraz maszyna abstrakcyjna mogą być użyte zarówno do pełnej ewaluacji termów jak i do obserwacji postępu krok po kroku.
Dodatkowo w mojej pracy opisuję proces integracji ze środowiskiem programistycznym języka \Racket{}, które pozwala na użycie implementacji rachunku jako podstawy minimalnego języka programowania.
}%
\englishabstract{%
Algebraic effects are an increasingly popular technique of structuring computational effects.
They allow for separation of an interface of a computation -- a set of operations it may perform, and their implementation -- handlers which respond to operation invocations.
There are many calculi and languages that tackle the concept of algebraic effects, but they are usually either specialized and developed with heavy-weight formalization, or they strive to become full-fledged programming languages with their meta-theory and implementation becoming increasingly complex.
In this thesis I set out to build a small calculus that has just enough general purpose constructs to allow for exploration and experimentation with algebraic effects and handlers without overburdening the user.
The meta-development consists of the Curry-style type system, the reduction semantics and the abstract-machine.
The calculus is built using the \Redex{} library and allows the programmer to use operations and handlers, recursive functions, numbers, booleans, lists and conditional expressions.
The implementation of the type system provides type inference for the calculus terms while both the reduction relation and the abstract machine can be used to either fully evaluate the expressions or visualize the reductions step-by-step.
Additionally I present the process of integrating this development with the \Racket{} environment that allows for usage of the calculus as a lightweight programming language.
}
%
\author         {Maciej Buszka}
%
\advisor        {dr hab. Dariusz Biernacki}
%\date          {}                     % Data złożenia pracy
% Dane do oświadczenia o autorskim wykonaniu
%\transcriptnum {}                     % Numer indeksu
\advisorgen     {dr. hab. Dariusza Biernackiego}
\let\lll\undefined
\usepackage[style=english]{csquotes}
\usepackage{amsmath, amssymb, float, ebproof}
\usepackage{minted, subcaption}
\usepackage{syntax}
%
\usepackage[xetex]{graphicx}
\usepackage[backend=biber,style=numeric,sorting=nty,language=english]{biblatex}
\addbibresource{mybib.bib}
\DeclareFieldFormat[article,inproceedings,incollection,book,misc,report]{title}{#1}
%
\floatstyle{boxed} 
\restylefloat{figure}
\restylefloat{listing}
%
\newcommand{\Redex}{\texttt{PLT Redex}}
\newcommand{\Racket}{\texttt{Racket}}
\newcommand{\LC}{\(\lambda\)-calculus}
\mathchardef\mhyphen="2D % Define a "math hyphen"
\def\listingautorefname{Listing}\addto\extrasenglish{%
  \renewcommand{\chapterautorefname}{Chapter}%
  \renewcommand{\sectionautorefname}{Section}%
}
%
\AtEveryBibitem{%
  \clearfield{month}
  \clearfield{url}
}
\begin{document}
%
\chapter{Introduction}
% dlaczego:
% experimentation with algebraic effects (calculus with various features)
% 
% lightweight prototyping
%
% goals:
% calculus
% implementation
% automatic testing (failed)
%
%
% What algebraic effects are, why are they interesting, why is it worth to experiment with different approaches/flavors
Algebraic effects~\cite{Plotkin2003} are an increasingly popular technique of structuring computational effects.
They allow for seamless composition of multiple effects, while retaining (unlike monads) applicative style of programs.
Coupled with handlers~\cite{Plotkin2013} which give programmers ability to interpret effects, they provide a disciplined and flexible tool for abstracting over a set of operations which a program may perform as well as separating this interface from the semantics of those operations defined as effect handlers.

% What are other approaches to algebraic effects
As composability and separation of concerns are sought after, many calculi and languages have been developed in order to get algebraic effects just right; most notable of them being: \emph{Koka}~\cite{Leijen2014} (featuring type inference, effect polymorphism with row-types and \emph{JavaScript}-like syntax), \emph{Links}~\cite{Hillerstrom2016} (featuring \emph{ML}-like syntax, row-typed effect polymorphism and ad-hoc effects), \emph{Helium}~\cite{Biernacki2019} (with abstract and local effects, \emph{ML}-style module system and principled approach to effect polymorphism), \emph{Eff}~\cite{Bauer2012} (with implicit effect checking and recent work on direct compilation to \emph{OCaml}~\cite{Kiselyov2018}) and \emph{Frank}~\cite{Lindley2017} (with shallow effect handlers and bidirectional type and effect system requiring minimal amount of effect variables). 

On a more theoretical side, various approaches to semantics of algebraic effects can be spotted in the literature, both with respect to type systems and run-time semantics.
Although most calculi use some form of row-types (with notable exception of \emph{Frank}~\cite{Lindley2017}) to track effects, there are differences in permitted shapes (at most one effect of given type~\cite{Hillerstrom2016} or many effects~\cite{Biernacki2017,Leijen2014}, whether effects must be defined before use~\cite{Biernacki2017,Lindley2017,Leijen2014,Bauer2012} or not~\cite{Hillerstrom2016}) and how effects interact with polymorphism and abstraction.
At run-time handlers can wrap the captured continuation (giving so-called deep handlers~\cite{Biernacki2017,Hillerstrom2016,Leijen2014,Bauer2012}) or not (shallow handlers~\cite{Lindley2017}) and the very act of finding the right handler can be implemented in various ways, mainly depending on some constructs which skip handlers~\cite{Biernacki2017}. 

% What am I implementing, what is interesting in this thesis, how it differs from other systems/languages (The main goal of the thesis)
% Goals:
%  runnable calculus with algebraic effects
%  user friendly (usable, machine executable, algorithmic) type system
%  introspectable reductions
%  runnable abstract machine
%  language front-end facilitating ease of experimentation
%  some lightweight machine checking (automatic tests)
All this variety naturally invites us to experiment with different features and components of a calculus.
An executable model would be excellent for anyone interested in understanding the inner workings of algebraic effects.
In particular, the ability to perform and visualize reductions would be very helpful in grasping the dynamic semantics of operations and handlers.
Such model should contain a type system complementing the dynamic semantics as well as providing guidance for the programmer with the proper usage of effects.
In this thesis I have built such a calculus, describing my choices and discussing the trade-offs encountered.

The first goal of this thesis is the design of the calculus with effects and handlers together with its dynamic semantics.
Its implementation should be executable and allow for step-by-step reduction of calculus terms by a computer program.
The second goal is the design and implementation of a sound type system for the above mentioned calculus, preferably with type inference.
The implementation should be able to type-check examples with minimal additional context and boilerplate.
The third goal is the design and implementation of an abstract machine, which preserves the dynamic semantics of the calculus yet is easier to translate into low-level virtual machine.
It could also be used as a basis for compilation to native code.

In order to rapidly iterate on the design and test the calculus, I decided to use the \Redex{} library which allows for building a language model with executable type system judgments and reduction relation.
It also provides facilities for visualization of rewriting of terms and typesetting all components of the development.

The calculus is designed to be small enough to be easily understood yet have general language features to allow experimentation with reasonably complex programs.
A programmer can use $\lambda$-abstractions and recursive functions, numbers with addition, subtraction, multiplication and comparisons, booleans with conditional expressions as well as lists.
Algebraic effects are implemented with ad-hoc operations (that need not be defined a priori) which take one parameter and return a single value, handlers which can handle multiple (different) operations at once and lifts which allow operations to skip handlers.
A handler wraps captured continuation, giving the deep handling semantics~\cite{Leijen2014}.
The type system for calculus is presented in Curry style with the implementation inferring simple types for unannotated terms using unification algorithm.
Although there is no way to create and bind polymorphic values, the system infers most general (simple) type for an expression which may contain unsolved variables.
The abstract machine is implemented with an explicit stack of continuations and value environment.
The machine is given a deterministic transition system using \Redex{}'s reduction relation and meta-function transforming a calculus expression into an initial configuration.
Additionally, I implemented a language front-end integrated with \Racket{} environment which translates human-friendly programs to calculus terms to facilitate user experimentation

In brief summary, the development consists of:
\begin{itemize}
  \item Executable reduction semantics most similar to the system of~\cite{Biernacki2017}.
  \item Curry style type system with ad-hoc effects in the style of \emph{Links}, effect rows based on \emph{Koka} and \emph{lift} construct of~\cite{Biernacki2017}, implemented as a unification-based type inference algorithm.
  \item CEK style abstract machine with stack and \emph{meta}-stack of handlers, based on~\cite{Hillerstrom2016}.
\end{itemize}

% Outline of the thesis
The rest of this thesis is structured as following: the remainder of this chapter introduces the main topics of this thesis; \autoref{ch:calculus} describes the calculus in greater detail; then in \autoref{ch:implementation} I discuss technicalities of implementation and integration with the \Racket{} environment and finally, \autoref{ch:manual} contains user's manual.

\section{Algebraic effects and handlers}
\begin{listing}[t]
  \VerbatimInput[firstline=13,lastline=19]{../algeff/test/05.rkt}
  \caption{Exception-like usage of algebraic effects}
  \label{lst:exception-like}
\end{listing}
Algebraic effects and handlers are a language-level framework which allows for a coherent presentation, abstraction, composition and reasoning about computational effects.
The key idea is to separate invocation of an effectful operation in an expression from the meaning of such an operation.
When one invokes an operation, the current continuation (up to the nearest handler) is captured and passed along with the operation's argument to the nearest handler.
The handler in turn may execute an arbitrary expression which uses the continuation once or twice, returns a function that calls the continuation or simply ignores it.
In this way many control structures can be modeled and generalized by algebraic effects and appropriate handlers.

For example, in \autoref{lst:exception-like}, function \texttt{exists} returns \texttt{true} when a list contains the element that satisfies predicate \texttt{p}.
It is implemented in terms of \texttt{map} and a helper function \texttt{f} which \texttt{Break}s normal control flow when the predicate returns \texttt{true}.
This map is then invoked inside the handler that returns \texttt{true} on \texttt{Break} and \texttt{false} otherwise.
This usage of operation and its handler is similar to exceptions, as the resumption is discarded.
Another example, with a handler for the state-like operations is presented in \autoref{lst:stateful-computation} in the next section.

From the language design standpoint algebraic effects provide single implementation of various phenomena which may happen during execution of a program such as mutable state, I/O, environment lookup, exceptions, etc.
With every effect being treated the same, the typing rules are defined for invocation of any operation, and handling of any operation.
Consequently, the operational semantics is simpler and succinct thanks to uniform treatment of various effects.
This framework is also extendable.
With small changes it can handle built-in effects in addition to user-defined ones.

From the language user perspective algebraic effects provide means of abstraction over effects used in a program.
Thanks to simplicity of creation of new effects, one can define special purpose operations and their handlers to better represent domain specific problems while simultaneously using well known effects defined in the standard library.
With effects being tracked by the type system, programmers can enforce purity or specific set of used effects at compile-time.
Using effect polymorphism they can write reusable functions that abstract over effects which may happen.
The separation of definition and implementation of effects allows for various interpretations of operations, e.g., simulating a database connection instead of connecting to a real one.
% TODO anonymous vs defined effects, abstract effects, effect polymorphism

\section{Types and type inference}\label{sec:types}
\begin{listing}[t]
  \begin{Verbatim}
let add = λ x Set +(Get (), x) in
let comp = 
  handle add 5 with
  | Set x r -> λ _ r () x
  | Get _ r -> λ s r s s
  | return _ -> λ s s
  end in
comp 37
  \end{Verbatim}
  \caption{Stateful computation}
  \label{lst:stateful-computation}
\end{listing}
The most common approach to give an effectful computation a type uses a type-level data-structure known as a row.
Initially developed in order to structurally type records, rows come in two flavors: Remy-style~\cite{Remy1994} where they are treated as (finite) sets of label-type pairs and Leijen-style~\cite{Leijen2005} where rows are treated as (finite) lists of label-type pairs that are equivalent up to permutation of different labels.
When polymorphism is present a row may have a concrete prefix (possibly empty) and a polymorphic tail denoted by a type variable.
In effectful setting, the type system usually keeps a row of effects which an expression may perform.
Suspended computations, e.g., functions must have types decorated with a row of operations that may be invoked when their body is evaluated.

In \autoref{lst:stateful-computation}, the function \texttt{add} loads a number, sums it with the argument \texttt{x} and sets this sum, returning unit value.
It contains two effectful sub-expressions: $Get \, : \, Unit \Rightarrow Num$ and $Set \, : \, Num \Rightarrow Unit$.
The operation type $Get \, : \, Unit \Rightarrow Num$ means that the operation $Get$ expects an argument of type $Unit$ and when it is handled the resumption will be given a value of type $Num$.
As the \texttt{add} function uses both operations, their effects must be combined giving it the following type: $Num \rightarrow (Get \, : \, Unit \Rightarrow Num , Set \, : \, Num \Rightarrow Unit) \, Unit$ where $Num$ is the type of input, $Unit$ is the type of output and $(Get \, \ldots)$ is the effect row.
The handler interpreting the operations is implemented as a state transforming function.
The type system requires all handler bodies to be of the same type: $Num \rightarrow () \, Num$ which guides the implementation and ensures that operations do not escape the handler.
When the \texttt{Set} operation is invoked, the handler returns a function.
This function will ignore the argument and resume the computation with unit value.
When this resumption returns a new state transformation -- representing the rest of the stateful computation, the function will call it with the new state \texttt{x} that was passed to the handler.
Similarly, the \texttt{Get} operation handler returns a function which awaits for a state $s$ with which it resumes the continuation and also passes it to the returned function.
The return clause returns the identity state transformation.
The soundness of this solution crucially depends on the deep handling semantics to ensure that the result of resumption will indeed have the same type as every clause.

Type inference is a technique of algorithmic reconstruction of types for various constructions used in a language.
It allows programmers to write programs with no type annotations, that often feel redundant and obfuscate the meaning of a program.
The most well known type system with inference is a system for \emph{ML} family of languages~\cite{Pierce2002} -- \emph{Haskell}, \emph{OCaml}, \emph{SML} which infers the types with no annotations whatsoever.
A formal type system defines grammar of types consisting of base types (\texttt{int}, \texttt{bool} etc.), type constructors (arrows, algebraic data types) and type variables.
The typing rules require types which should be compatible (e.g. formal parameter and argument types) to unify.
The key feature of this system is the so-called let-polymorphism -- generalization of types of let-bound variables.
This way code reuse can be accomplished without complicating the type system and compromising type safety.
The basis of implementation of this system is the first-order unification algorithm~\cite{Pierce2002}, which syntactically decomposes types and builds a substitution from type variables to types.

\section{Reduction semantics and abstract machines}
% TODO add reference to canonical definitions for good definition of reduction semantics and abstract machines, especially CEK
Reduction semantics~\cite{Felleisen2009} is a format for specifying dynamic semantics of a calculus in an operational style.
The basic idea is to first define redexes -- expressions which can be reduced, and contexts in which the reduction can happen.
Taking \LC{} extended with numbers (\autoref{fig:lc-syntax}) and with call-by-value reduction order as an example, the only redex is an application of a function to value $ (\lambda x . e) v $ as shown in \autoref{fig:lc-red}.
The possible contexts are: empty context $[]$ or evaluation of the operator part of an application $ K e $ or evaluation of the operand $ v K $ when the left part has already been reduced to a value.
\begin{figure}[t]
  \includegraphics{lc-syntax.pdf}
  \caption{\LC{} abstract syntax}
  \label{fig:lc-syntax}
\end{figure}
With these possibilities in mind, we will define binary relation $ \longrightarrow $ which describes a single step of reduction.
Such relation can be thought of as a transition system, rewriting terms into 'simpler' ones step by step.
There usually are two approaches to a definition of such a relation:
\begin{itemize}
  \item Definition of primitive reduction $ (\lambda x . e) v \longrightarrow_p e\{v/x\} $ which operates only on redexes and giving it a closure with the following inference rule:
  
  \begin{prooftree}
    \Hypo{e \longrightarrow_p e'}
    \Infer1{K[e] \longrightarrow K[e']}
  \end{prooftree}

  which says that if we can primitively reduce some expression, then we can do it in any context.
  \item Or definition of $ \longrightarrow $ directly, with decomposition of terms on both sides: $ K[(\lambda x . e) v] \longrightarrow K[e\{v/x\}] $
\end{itemize}
where the syntax $ e\{v/x\} $ means term $ e $ with value $ v $ substituted for variable $ x $ and $ K[e] $ means some context $ K $ with expression $ e $ inserted into the hole.
For both approaches it is important, that any term can be uniquely decomposed into redex and context, as if it is the case then the relation is deterministic and gives good basis for formulation of abstract machines, interpreters or transformations to some other intermediate representations.
\begin{figure}
  \includegraphics{lc-red.pdf} 
  \caption{\LC{} reduction relation}
  \label{fig:lc-red}
\end{figure}

Abstract machine is a mathematical construction, usually defined as a set of configurations with deterministic transformations, which are computationally simple.
The goal for formulation of an abstract machine is to mechanize evaluation of terms while retaining semantics given in a more abstract format, e.g., reduction semantics with the correspondence being provable~\cite{Felleisen2009}.
As an example, \autoref{fig:lc-cek} shows a \emph{CEK}-machine for the \LC{} defined above.
The name \emph{CEK} comes from \emph{C}ommand, \emph{E}nvironment and \emph{K}ontinuation.
The machine has two configurations.
The first is a triple $ (e, \rho, \kappa) $ where $ e $ is an expression which is decomposed, $ \rho $ is an environment mapping variables to values, and the last component $ \kappa $ is a continuation stack.
It determines what will happen once the machine enters the second configuration -- a pair with a tag $val$ specifying that machine has computed a value and will have to pop a continuation frame.
There are two possible frames: an argument expression with the environment awaiting reduction and the function value awaiting for the argument.
The transition rules \textit{val-x}, \textit{val-n} and \textit{val-$\lambda$} switch to the second configuration upon encountering a value.
The rule \textit{push-e} sequences the application, by first evaluating the function expression, pushing the argument computation onto the stack.
The rule \textit{push-$\lambda$} finishes the sequencing by popping the argument with its environment and pushing the function value.
The rule \textit{$\beta$} performs the reduction by popping the function from the stack and extending the environment for the evaluation of the body.
Finally, the rule \textit{done} returns the value when there is no more computation to be done.
Thanks to the environment we no longer have to explicitly perform substitution, leading to more machine friendly and efficient implementation.
Given an initial state, the machine can then repeatedly apply transition relation, either looping, arriving at a final value, or getting stuck. 
\begin{figure}
  \centering
  \begin{subfigure}{0.3\textwidth}
    \includegraphics{lc-am-syntax.pdf}
  \end{subfigure}
  \begin{subfigure}{0.69\textwidth}
    \includegraphics{lc-am.pdf}
  \end{subfigure}
  \caption{\LC{} abstract machine}
  \label{fig:lc-cek}
\end{figure}

\section{\Redex}
The \Redex{}~\cite{Felleisen2009} library provides a comprehensive set of tools for the development of various calculi and language-like artifacts.
The work begins with the definition of a language using a familiar BNF-like syntax.
The library provides many options for defining patterns which describe the abstract syntax of the language, among them: meta-variables, symbols -- playing the role of markers, numbers, object language variables, repetitions of patterns using ellipsis and nonlinear patterns which can for example enforce that all variables in a binding are different.
Besides the syntax, the language definition allows for specification of a variable binding structure of the object language, which is used by the built-in meta-function for substitution.
\autoref{lst:lc-typed-syntax-code} shows code which extends the \LC{} defined in \autoref{fig:lc-syntax} with typed terms $ E $, along with types $ t $ and typing contexts $ \Gamma $.
\begin{listing}[t]
  \inputminted[firstline=26, lastline=32]{Racket}{../lc/lc.rkt}
  \caption{Typed \LC{} with numbers in \Redex{}}
  \label{lst:lc-typed-syntax-code}
\end{listing}
Another feature of the \Redex{} library are meta-functions which can pattern match on terms and return other terms.
They may use the full power of complex and non-linear patterns which the library exposes, additional side conditions and even escape to \Racket{} -- the host language in which the \Redex{} is defined.

\begin{listing}[t]
  \inputminted[firstline=34,lastline=51]{Racket}{../lc/lc.rkt}
  \caption{Type system for \LC{} in \Redex{}}
  \label{lst:lc-typed-type-code}
\end{listing}

The third aspect of this library are judgment forms which encode inductively defined judgments (e.g., type systems) with a syntax similar to pen-and-paper rules. \autoref{lst:lc-typed-type-code} shows example code, defining a simple type system for annotated \LC{} with numbers.
These rules can use patterns, meta-functions, other judgments and also escape to \Racket{}.
When defining a judgment, the programmer must specify which parameters are to be treated as inputs and which as outputs using the \mintinline{Racket}{#:mode} keyword.
The library enforces an invariant that inputs \texttt{I} of a judgment form must be concrete terms and outputs \texttt{O} may be variables.
Under the hood the \Redex{} library will resolve the rules in depth-first order backtracking on failures and multiple pattern matches.

The last component of a language that can be modeled using \Redex{} are reduction relations, usually used for specifying semantics.
They are defined as a set of clauses which should rewrite an input term into other term of the same syntactic category.
In order to find a redex, the programmer can define evaluation contexts; then the library will decompose the terms using \mintinline{Racket}{(in-hole K e)} pattern, as in \autoref{lst:lc-red-code}.
\begin{listing}[t]
  \inputminted[firstline=19,lastline=23]{Racket}{../lc/lc.rkt}
  \caption{Reduction relation for \LC{} in \Redex{}}
  \label{lst:lc-red-code}
\end{listing}
Finally \Redex{} provides features for automatic testing via term generation facilities. The library has as well the ability to typeset every component of the calculus development.
Every figure in this thesis, which shows language grammar, reduction relation, meta-function or judgment has been generated using \Redex{}.

\chapter{The calculus}\label{ch:calculus}
The calculus implemented in this thesis is based on \LC{} with call-by-value semantics.
Its abstract syntax is presented in \autoref{fig:algeff-syntax}.
Meta-variable $ x $ ranges over variables used in value binders and their references, while $ op $ ranges over operation names which are distinct from normal variables.
Meta-variable $ v $ ranges over values which are one of: boolean $ b $, number $ m $, $ \lambda $-abstraction $(\lambda \, x \, e)$, recursive function $(rec \, x_f \, x_v \, e)$ or a list of values $(v \ldots)$.
Meta-variable $ e $ ranges over expressions which include values $ v $, forms standard to \LC{} -- variables $ x $, function applications $ (e \, e) $, conditionals $ (if \, e \,e \, e) $ and primitive operations $ (prim \, e \ldots) $; they also include three constructs specific to effects -- operation invocations $ (op \, e) $, lifts $ (lift \, op \, e) $ and handlers $ (handle \, e \, hs \, ret) $ where $ ret $ is return expression $ (return \, x \, e) $ and $ hs $ is a list of handler clauses.
Each operation may occur at most once in the list and the clause $(x_{!\_1} \, x_{!\_1} \, e)$ for the operation requires bound variables to be distinct.

To achieve call-by-value, left-to-right reduction order I use evaluation contexts $ E $; this choice follows other calculi which allow for computational effects~\cite{Biernacki2017, Leijen2014, Hillerstrom2016}.
One interesting aspect of these contexts is notion of \emph{free}ness~\cite{Biernacki2017}, defined in \autoref{fig:algeff-free}.
The judgment $ free[ \, op , \, E , \, n] $ asserts that operation $ op $ is $ n $-free in evaluation context $ E $, meaning that it will be handled by $(n + 1)$st handler for $ op $ \emph{outside} the context $ E $.

The syntax of types, ranged over by meta-variable $ t $, comprises base types ($Num$, $Bool$), lists $List \, t$, arrow types $(t \rightarrow row \, t)$, operation types $(t \Rightarrow t)$, row types $row$ and type variables $ a $.
Rows are defined inductively as either an empty row $\cdot$, a variable $ a $ or an extension $(op \,\, t \,\, row)$ of a row $row$ with a type $t$ assigned to an operation label $op$, and are ranged over by meta-variable $row$.
Finally, meta-variable $\Gamma$ ranges over typing contexts, $S$ over type substitutions and $SN$ denotes a pair of substitution and name supply $N$ -- a natural number used to generate fresh type variables.

\begin{figure}
  \centering
  \includegraphics{algeff-syntax.pdf}
  \caption{Abstract syntax}
  \label{fig:algeff-syntax}
\end{figure}

\begin{figure}
  \centering
  \includegraphics{algeff-free.pdf}
  \caption{Context \emph{free}ness}
  \label{fig:algeff-free}  
\end{figure}

\section{Dynamic semantics}
The dynamic semantics for a calculus with algebraic effects defines, besides the standard reductions known from \LC{}, the control structure of operations and handlers.
Intuitively, when an operation $op$ is invoked, it will be handled by dynamically closest handler, with a caveat that for each lift passed in search of handler, it must skip one handler.
Formally, when an operation $ op $ is invoked, it will be handled by lexically enclosing handler $ (handle \, E[op \, e] \, hs \, ret) $ if and only if the intermediate context $ E $ is $0$-free~\cite{Biernacki2017}.

The dynamic semantics is defined in the format of contextual reduction semantics in \autoref{fig:algeff-red}.
All rules perform reduction in a context $ E $ leaving it unchanged.
The first rule $\beta\mhyphen\lambda$ describes standard $ \beta $-reduction via substitution of argument value for variable in function body while the second $\beta\mhyphen rec$ is the $ \beta $-reduction of recursive function where first we substitute the function for function variable and then substitute the argument.

The rule \emph{prim-op} deals with built-in primitive operations using helper meta-function \textit{prim-apply} which pattern matches on $prim$ and performs the appropriate operation.
Next two rules \emph{if-true} and \emph{if-false} perform a choice of the correct branch in a conditional expression depending on the value of the condition.
The rule \emph{lift-compat} returns a value from a lift expression, leaving it unchanged.

The rule \textit{handle-return} handles the case when the inner expression of a handle expression evaluates to a value, which means we have to evaluate the return clause by substituting the result value for $ x $, and plugging this expression into the evaluation context $ E $.

The last rule \textit{handle-op} describes the behavior when an expression calls some operation.
To handle an operation we must find a $0$-free inner context $ E_2 $ which is directly surrounded by a handle expression which has a case for $ op $.
Then we substitute the value $ v $ for the first variable $x_1$ of the operation handler and the inner context $ E_2 $ surrounded with the very same handler (the continuation delimited by the handler) closed in a lambda for the second argument $x_2$.
This wrapping gives deep handling semantics as an operation call cannot escape from a handler in the resumption.
The operation handler can resume the evaluation of the expression which invoked the handled operation using the function bound by $x_2$.

\begin{figure}
  \centering
  \includegraphics{algeff-red.pdf}
  \caption{Reduction relation} 
  \label{fig:algeff-red}
\end{figure} 

\section{Static semantics}
The type system is based on \emph{Koka}~\cite{Leijen2014} (Leijen's style of row types~\cite{Leijen2005}), \emph{Links}~\cite{Hillerstrom2016} (ad-hoc operations) and Biernacki et al's.~\cite{Biernacki2017} (lift construct) systems.
Initially I implemented a variant of System F extended with row-types but it proved to be a bit of a mouthful to write in it even the simplest programs.
Additionally the \Redex{}'s facilities for generation of terms were not able to generate enough well typed ones.
As I intended on using the automated counter-example search to test assertions about the calculus, my goal was to minimize the number of programs rejected by the type system.
In order to accomplish this goal type inference proved to be very helpful as it increased the amount of well typed terms ten-fold.

To limit the amount of work and keep the calculus reasonably simple, I decided to present the calculus in the Curry style.
The implmentation of typing relation infers the type for unannotated terms.
In this way I avoided implementing a separate type system and inference algorithm.

Building on well known foundations~\cite{Pierce2002}, types are inferred via first-order unification.
While the actual algorithm is presented in \autoref{sec:unification}, the notion of unification is used extensively in the remainder of this chapter and as such I will present an intuitive definition here.
Two types $t_1$ and $t_2$ \emph{unify} (written $t_1 \sim t_2$) if they are structurally the same where variables can be substituted with any simple type.
Two rows unify, if they are the same list of operation-type pairs, up to permutation of different operations.

The system does not feature polymorphism in a first-class fashion, as no polymorphic functions can be bound, mainly because there is no rule where types are generalized, but I believe it to be a straightforward addition, following the \emph{Koka}~\cite{Leijen2014} calculus.
Nevertheless, having inferred the type of an expression one can see which unification variables are left abstract and could be generalized.
There are two main features differentiating this system from \emph{Koka}'s; firstly effects need not be defined before use as their signature is inferred the same way as any other construction; secondly the system is algorithmic with rules explicitly encoding a recursive function which can infer the type of an expression.

\subsection{Type inference}
The judgment $ \Gamma \mid [S_1 \, N_1] \vdash e \, : \, t \, ! \, row \mid [S_2 \, N_2] $ asserts that in a typing context $ \Gamma $ under a type substitution $ S_1 $, with name supply state $ N_1 $, expression $ e $ has type $ t $ with effects $ row $ under a type substitution $ S_2 $ and with a name supply state $ N_2 $.
Algorithmically this judgment infers a type and an effect row, and calculates new substitution given typing environment, current substitution and an expression.
As in \emph{ML} languages only simple types along with effect rows can be inferred.
The judgment rules are presented in \autoref{fig:algeff-infer}.

\begin{figure}
  \centering
  \includegraphics{algeff-infer.pdf}
  \caption{Type system} 
  \label{fig:algeff-infer} 
\end{figure}

Base rules for constants (\emph{Bool} and \emph{Num}) check whether the value is of the appropriate category and the rule for variables \emph{var} looks the type up in the environment $\Gamma$ each introducing fresh effect row variable.
To check $ \lambda $ expression with rule $\lambda$ we first introduce fresh type variable and then check the body in the extended environment.
The arrow gets annotated with effects which may occur during evaluation of the body and the $ \lambda $ abstraction itself is returned with a fresh effect row.

The recursive functions are checked using rule \emph{rec} in a fashion similar to normal functions.
First variable $x_f$ denotes function itself while second $x_a$ its argument.
Accordingly, the environment $\Gamma$ gets extended with functional type $ t_1 \rightarrow row_1 t_2 $ for $x_f$ and argument type $ t_1 $ for $x_a$ to check the body of the function.
Afterwards the result type of body $ t $ gets unified with the result type of function $ t_2 $, same with effect row.
The whole function, as it is a value, is returned with a fresh effect row.

The rule \emph{app} for application requires the expression $e_1$ at function position to be of functional type and the expression $e_2$ at argument position to have a type that unifies with the parameter type of the function. 
All effect rows (from evaluation of $e_1$, $e_2$ and the body of the $\lambda$) must unify as well.
Inference for primitive operation call in rule \emph{prim} is deferred to auxiliary judgment \emph{check-prim} which checks arity and argument types returning result type and usually fresh effect row.
The rule \emph{if} for conditional expression requires the condition to be of type $ Bool $ and types of two branches to unify.
As usual all effect rows must also unify.

Operation invocation, checked by the rule \emph{op}, requires the effect row to contain operation $ op $ with type $ (t_1 \Rightarrow t_2) $ where input type $ t_1 $ is the inferred type for $ e $ and output type $ t_2 $ is fresh.
The rule \emph{lift}, checking operation lifting, prepends fresh $ op $ to the effect row of sub-expression $e$.

Finally, to check handle expression with the rule \emph{handle}, we infer the type $t_1$ of the enclosed expression $e$.
Then in an environment extended with the type $t_1$ we infer the type $t_{ret}$ of the return expression.
Helper judgment \textit{infer-handlers} returns the result effect row of handlers $row_{out}$ and row marking handled effects $ row_{handled} $ with the same tail as $row_{out}$.
By unifying result row with return row and handled row with $row_1$ we ensure that effects which may occur during handling of operations, evaluation of return clause and leftovers from the inner expression are all accounted for.

\subsection{Type inference for effect handlers}

\begin{figure}
  \centering
  \includegraphics{algeff-infer-handlers.pdf}
  \caption{Type inference for effect handlers} 
  \label{fig:algeff-infer-handlers} 
\end{figure} 

List of effect handlers $ hs $ is processed right-to-left by the judgment 
$$ infer\mhyphen handlers [\Gamma , \, SN_{in} , \, t_{ret} , \, hs , \, row_{out} , \, row_{handled} , \, SN_{out}] $$
presented in \autoref{fig:algeff-infer-handlers}.
The $ t_{ret} $ is the type of the return clause, $ row_{out} $ is the combined row of effects which may occur in any handler and $ row_{handled} $ is the row of handled operations with appropriate types.
The base case of empty list initializes both rows with the same type variable.
This way $ row_{handled} $ returned by the $infer\mhyphen handlers$ judgment will consist of all handled operations and its tail will be $ row_{out} $.
The inductive case first calculates $ row_{out} $ and $ row_{handled} $ for the tail of the list.
Then two new fresh variables are created: $ t_v $ for the type of value passed to handler and $ t_r $ for the type of resumption parameter.
Resumption's result type is the result type of return clause as it should eventually evaluate to a value which will be transformed by that clause.
Its effect row is the same as the result row of whole handle expression which means that any subsequent uses of operations will be handled by this handler.
With the environment extended with $ t_v $ for the first parameter -- an argument to the handler expression and $ t_r \rightarrow row_{out} \, t_{ret} $ for second parameter -- the resumption, we check the handler expression $ e $.
We then unify the effects of evaluating $ e $ with all effects of handlers, and result type $ t_{h} $ with the return type $ t_{ret} $.
Finally we extend the handled row with the current operation $(op (t_v \Rightarrow t_r))$.

\section{Abstract machine}
The abstract machine is based on the \emph{CEK}-machine of Hillerström and Lindley~\cite{Hillerstrom2016}, with the difference that during the search for operation handler, the machine must count handlers and lifts it passes.
It is similar to the abstract machine presented in extended version of Biernacki et al's~\cite{Biernacki2017} as both calculi have the \emph{lift} construct.

\begin{figure}[t]
  \centering
  \includegraphics{algeff-am-syntax.pdf}
  \caption{Abstract machine configurations}
  \label{fig:algeff-am-syntax}
\end{figure}

Possible configurations are given in \autoref{fig:algeff-am-syntax}.
Meta-variable $ C $ ranges over shapes of machine configurations, meta-variable $ V $ ranges over machine values, which are distinct from the calculus values, e.g., function values must now keep their environment $ \rho $ which maps variables to machine values.
Additionally one of the possible values is a \emph{meta-stack} which one may think of as a continuation captured during operation invocation.
Meta-variable $ \sigma $ defines normal (or pure) continuation frames and $ \Sigma $ denotes pure continuation \emph{stack}, while $ \phi $ ranges over effect frames -- \texttt{handle}, \texttt{lift} and \texttt{done} token which marks final continuation.
Meta-variable $ \kappa $ denotes meta-frame which consists of a pure stack and one effect frame.
Finally $ K $ ranges over stacks of meta-frames which I will call \emph{meta-stack}s.
Meta-function \textit{initial-conf} in \autoref{fig:algeff-am-initial-conf} transforms an expression into initial configuration -- initializing machine with empty stack, \texttt{done} effect frame and empty meta-stack.

\begin{figure}[t]
  \centering
  \includegraphics{algeff-am-initial-conf.pdf}
  \caption{Abstract machine -- initial configuration}
  \label{fig:algeff-am-initial-conf}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics{algeff-am-a.pdf} 
  \caption{Abstract machine -- administrative transitions}
  \label{fig:algeff-am-a}
\end{figure}

The first group of transitions depicted in \autoref{fig:algeff-am-a} performs mostly administrative functions -- capturing environment for functional values, transforming from value terms to machine values, sequencing primitive operations, switching to special configuration for search of a handler and a transition for returning the final value.

\begin{figure}[t]
  \centering
  \includegraphics{algeff-am-b.pdf} 
  \caption{Abstract machine -- continuation building}
  \label{fig:algeff-am-b}
\end{figure}

The second group of transitions (\autoref{fig:algeff-am-b}) decomposes current expression and builds continuation by growing either stack or meta-stack.
First four rules -- for function application, operation invocation, primitive operation call and conditional expression -- all create a new pure frame and push it onto stack.
Last two transitions deal with effectful operations -- handle and lift; they build meta-stack by bundling previous effect frame with current stack into meta-frame, pushing it onto meta-stack and then installing a fresh stack and a new effect frame into the machine configuration.

\begin{figure}[t]
  \centering 
  \includegraphics{algeff-am-c.pdf}
  \caption{Abstract machine -- contractions}
  \label{fig:algeff-am-c}
\end{figure}

The third group of transitions (\autoref{fig:algeff-am-c}) perform various reductions.
The first rule looks up value of a variable in current environment, the second rule performs contraction of a normal function, by extending the environment with mapping from the function's formal parameter $ x $ to the calculated value $ V $.
The third rule reduces recursive function, extending the environment with the argument value $ V $ and the function value allowing for recursive calls.
The last rule handling application deals with continuation resumption, by pushing the current stack and the effect frame ($ [(\sigma \ldots) \, \phi_1] $) onto the meta-stack, installing the top ($ [\Sigma \, \phi_2] $) of captured meta-stack and prepending its tail ($ (\kappa_1 \ldots) $) to the meta-stack.
The first of the remaining rules applies the primitive operation to the arguments and the following rules perform the choice of the correct branch in a conditional expression.

\begin{figure}[t]
  \centering
  \includegraphics{algeff-am-e.pdf}
  \caption{Abstract machine -- effect handling}
  \label{fig:algeff-am-e}
\end{figure}

Transitions in the last group (\autoref{fig:algeff-am-e}) form the essence of this machine, performing all tasks related to effect handling.
First four rules search for the appropriate handler for $ op $ by maintaining a counter $ n $ which is incremented by every lift for $ op $ and decremented by every handler for $ op $.
The fifth rule matches when the counter is $ 0 $ and the handler has a case for the operation which was invoked. 
In this situation, the machine must begin evaluation of the handling expression in the environment extended both with the passed argument and the captured continuation with current meta-frame appended.
The last two rules deal with returning values -- in case of a handler the return clause is installed and in case of a lift its frame is simply discarded.

\chapter{Implementation}\label{ch:implementation}
This chapter discusses the implementation of the calculus and its surface language \emph{algeff}.
All the judgments and relations presented earlier were rendered by the \Redex{} library from the source files and they are the executable implementation of the calculus.
The unification algorithm used by the type inference judgment of \autoref{fig:algeff-infer} is presented in \autoref{sec:unification}.
\autoref{sec:file-structure} describes the file structure of the development, \autoref{sec:front-end} discusses the language front-end and \autoref{sec:racket-env} shows how to tie a language into the \Racket{} environment.
The surface syntax of \emph{algeff} and the instructions of use are presented in \autoref{ch:manual}.

\section{Unification}\label{sec:unification}
The unification algorithm is loosely based on~\cite{Pierce2002}.
However, instead of keeping a set of constraints to be solved it solves sub-problems recursively.
It is implemented as a \Redex{} judgment that takes two types and the initial substitution and returns the substitution extended with their unifier.
This judgment must also pass around the name supply token -- a natural number which is incremented every time a new type variable is created.
Variables in types are substituted lazily -- whenever algorithm encounters variable which is in the domain of the substitution it looks it up and continues unification.
\autoref{fig:algeff-unify} shows the unification algorithm.

\begin{figure}
  \centering
  \includegraphics{algeff-unify.pdf}
  \caption{Unification algorithm}
  \label{fig:algeff-unify}
\end{figure}

\begin{figure}
  \centering
  \includegraphics{algeff-unify-row.pdf}
  \caption{Row unification algorithm}
  \label{fig:algeff-unify-row}
\end{figure}

Terminal rules \emph{refl-var} and \emph{refl-const} handle unification of equal variables and constants respectively.
In a special case \emph{refl-var-lookup}, when both types are variables, the left variable $a_1$ is not in the domain of the substitution and the right variable $a_2$ is mapped to $a_3$ which is equal to $a_1$ then they are in fact the same variable and should unify.
This corner-case arises due to lazy application of substitution to types.

The rule \emph{ext} extends substitution when the left-hand-side type is a variable which is not in the domain of substitution.
It is important to note that the type which is inserted into substitution is fully substituted.
This way we can maintain an invariant that every type in the substitution has only type variables which are not in the domain of the substitution.
The last side condition that $a$ is not a free type variable in $t$ is the occurs-check.
It ensures that algorithm does not try to unify cyclic types which would cause the algorithm to loop.

When the left type is a variable in the domain of substitution, rule \emph{lookup} looks it up and continues unification.
When the left type is not a variable and the right type is, rule \emph{flip} flips them around and continues unification.
This rule is needed because the judgment performs extension and lookup only on left variable.
The next three rules \texttt{->}, \texttt{=>} and \emph{List} decompose the type constructor and unify all respective sub-types.

The last rule \emph{row} unifies two rows.
It requires the left row to be non empty and the right row not to be a variable (to ensure determinism with respect to the rule \emph{flip}).
Then it uses helper judgment \emph{unify-row} which rewrites $row_2$ such that its head is $op \, \, t_2$ and the rest is bound to $row_r$.
The end of the (substituted) $row_1$ is bound to the variable $a$ and the substitution which resulted from the rewriting of $row_2$ is bound to $S_2$.
The side condition $a \notin dom\mhyphen S [\![S_2]\!] $ requires the variable $a$ not to be in the domain of $S_2$.
It ensures that the algorithm does not try to unify rows with different labels but the same type variable in the tail (similarly to occurs-check in the rule \emph{ext}).

The helper judgment \emph{unify-row}, shown in \autoref{fig:algeff-unify-row}, rewrites the row such that it begins with desired label $op$.
It is based on similar judgment in~\cite{Leijen2005}.
There are two base cases: either the row already begins with $op$ (rule \emph{row-head}) and is decomposed and returned or the row is already a variable which is not bound by substitution (rule \emph{row-var}).
In this case the substitution is extended with a row $(op \, t \, row)$ where both $t$ and $row$ are fresh variables.

The third rule \emph{row-lookup} handles variables which are bound by the substitution looking up the appropriate row and continuing row rewriting.
The last rule \emph{row-swap} matches rows that have a label $op_1$ different from the desired label $op_2$.
In this case, the rest of the row must be rewritten recursively yielding type $t_2$ for $op_2$ and a new tail.
The type is returned and the tail is extended with the original head.

\section{File structure}\label{sec:file-structure}
The directory \texttt{lc} contains the minimal \LC{} used in the introduction.
The development -- both calculus and \Racket{} front-end is contained in the directory \texttt{algeff}.
Its sub-directory \texttt{calculus} contains source files for everything calculus-related:
\begin{itemize}
  \item The file \texttt{abstract-machine.rkt} contains the definition of the abstract machine and its transitions.
  \item The file \texttt{eval.rkt} contains the reduction semantics and the \emph{free} judgment.
  \item The file \texttt{lang.rkt} contains the calculus abstract syntax definition and \emph{ftv} meta-function.
  \item The file \texttt{lib.rkt} contains various helper judgments and meta-functions.
  \item The file \texttt{type.rkt} contains the type system along with helper judgments.
  \item The file \texttt{unify.rkt} contains the implementation of the unification algorithm.
\end{itemize}
The sub-directory \texttt{lang} contains lexer and parser for the front-end.
The file \texttt{main.rkt} is evaluated by \Racket{} environment whenever a file designates \emph{algeff} as its \texttt{\#lang}.
The files \texttt{parse-only.rkt} and \texttt{tokenize-only.rkt} define sub-languages used for testing and debugging of the parser.
The sub-directory \texttt{test} contains example programs.
Finally, the file \texttt{render.rkt} renders the figures used throughout this thesis.

\section{Language front-end}\label{sec:front-end}
The language front-end consists of a tokenizer and a parser.
The tokenizer is implemented using \texttt{parser-tools} package which provides a \texttt{lex} style lexer generator.
It defines a set of tokens and then repeatedly partitions the input stream by matching it with regular expressions.
The parser is implemented using \texttt{megaparsack} -- a library providing various parser combinators which allow for composing simple parsers together to build complex ones in monadic style.
The parser desugars some surface expressions into simpler calculus terms.
\begin{itemize}
  \item Multiple applications which are permitted by the \emph{algeff} language are rewritten into nested single applications -- \texttt{f e$_1$ e$_2$ ... e$_n$} becomes \texttt{(app (... (app (app f e$_1$) e$_2$) ...) e$_n$)}
  \item Let-expressions \texttt{let x = exp in body} are transformed into an application: \texttt{(app (λ x body) exp)}.
  \item Letrec bindigs \texttt{letrec f x = exp in body} are similarly transformed: \texttt{(app (λ x body) (rec f x exp))}.
\end{itemize}
It also differentiates and marks variables and operation names.

\section{The \Racket{} environment}\label{sec:racket-env}
The \Racket{} environment~\cite{PLT1} provides easy integration with sub-languages using its sophisticated syntax-transformer system and language specifiers.
It allows programmers to choose which language should be used to interpret the source file using the \texttt{\#lang} command at the beginning of the file.
The file must eventually be transformed into module recognized by base \Racket{}.
This way programs may be composed with modules written using various domain-specific languages.
In order to allow \Racket{} to use a new language, its developer must provide:
\begin{itemize}
  \item The reader -- a function that accepts input stream and produces abstract syntax tree of a module.
  \item The expander -- a syntax transformer that accepts the tree produced by the reader and creates a \Racket{} module, which can be interpreted by the \Racket{} language.
\end{itemize}

I followed the `master recipe' described in~\cite{BeautifulRacket} that specifies which components and where must be defined.
The file \texttt{main.rkt} provides an inner module \texttt{reader} and a syntax transformer \texttt{\#\%module-begin} -- the expander.
The inner module provides a function \texttt{read-syntax} which transforms the program text provided on an input port, using the parser and tokenizer described earlier, into a single calculus term represented as \Racket{} \emph{syntax object}.
It is shown in \autoref{lst:the-reader}.
\begin{listing}[t]
  \inputminted[firstline=11, lastline=19]{Racket}{../algeff/main.rkt}
  \caption{The reader}
  \label{lst:the-reader}
\end{listing}
The expander is depicted in \autoref{lst:the-expander}.
It first type checks the expression which was created by the reader (lines 4 and 5), and if it succeeds, it will create a \Racket{} module that binds several names and return the value of the reduced expression.
To create bindings that will be visible when the generated module is opened in the \texttt{REPL} one must transform regular racket symbols into syntax objects with proper scope (lines 7-12).
It can be done using the \texttt{(datum->syntax ctx sym)} function which takes any syntax object and creates a new one from \texttt{sym} inheriting the scope from \texttt{ctx}.
The created module \texttt{require}s the \texttt{redex} package.
This package contains the \texttt{traces} function and \texttt{term} syntax form that are used in the module body.
The module defines variables containing the expression and its type, functions that can trace the reduction of the expression and functions that calculate the final value.
If the term does not typecheck the expander will raise an exception.
\begin{listing}[t]
  \inputminted[firstline=29,linenos=true,firstnumber=1,lastline=56]{Racket}{../algeff/main.rkt}
  \caption{The expander}
  \label{lst:the-expander}
\end{listing}

\chapter{User's manual}\label{ch:manual}
\section{Requirements and installation}
The \emph{algeff} language and the implementation of the underlying calculus requires:
\begin{itemize}
  \item A recent version of the \Racket{} environment (e.g. \texttt{7.0})
  \item The \Redex{} library -- usually part of the \Racket{} environment
  \item The \texttt{parser-tools} and \texttt{megaparsack} libraries
\end{itemize}
The libraries can be installed using either \texttt{raco} -- \Racket{}s package manager via the command \texttt{raco pkg install <library-name>} or with \texttt{DrRacket} graphical environment via \texttt{File > Install Package...} menu.

To install the \emph{algeff} language enter the \texttt{algeff} directory and run \texttt{raco pkg install}.
The \Racket{} environment should now recognize the \texttt{\#lang algeff} directive and interpret \emph{algeff} expressions.

\section{Usage and example programs}
To use the \emph{algeff} language create a file with \texttt{.rkt} extension and change the first line to \texttt{\#lang algeff}.
The file will be interpreted by the \emph{algeff} front-end inferring the type of the expression and producing a \Racket{} module containing following bindings:
\begin{itemize}
  \item \texttt{expression} -- the source expression.
  \item \texttt{type} -- the inferred type.
  \item \texttt{reduce} -- a procedure that evaluates the source expression using the reduction semantics.
  \item \texttt{reduce-machine} -- a procedure that evaluates the source expression using the abstract-machine.
  \item \texttt{trace} -- a procedure that traces the reduction of the expression.
  \item \texttt{trace-machine} -- a procedure that traces the abstract-machine execution of the source expression.
\end{itemize}

An example program calculating factorial of a number is presented in \autoref{lst:algeff-program}.
\begin{listing}[t]
  \VerbatimInput{../algeff/test/01.rkt}
  \caption{An \emph{algeff} program}
  \label{lst:algeff-program}
\end{listing}
After opening this program in the \texttt{DrRacket}'s definitions pane it can be interpreted giving following output in the interactions pane:
\begin{verbatim}
  Welcome to DrRacket, version 7.0 [3m].
  Language: Determine language from source; memory limit: 2048 MB.
  120
  >
\end{verbatim}
An example further interaction:
\begin{verbatim}
> expression
'(app
  (λ v:f (app v:f 5))
  (rec v:f v:x (if (== v:x 0) 1 (* v:x (app v:f (- v:x 1))))))
> type
'Num
> (reduce)
120
> (reduce-machine)
120
>
\end{verbatim} 
It is also possible to show step-by-step reductions:
\begin{verbatim}
> (trace)
; opens a new window with interactive reduction
> (trace-machine)
; opens a new window with interactive abstract machine transitions
\end{verbatim}

\begin{listing}[t]
  \VerbatimInput{../algeff/test/02.rkt}
  \caption{An \emph{algeff} program with effects}
  \label{lst:algeff-algeff-program}
\end{listing}

An example program with algebraic effects is shown in \autoref{lst:algeff-algeff-program}.
It defines the handler for state in the same style as described in \autoref{sec:types} with the difference that $0$ is used instead of the unit type.
The program uses this handler with a delayed stateful computation.
Evaluating this program should yield the result $24$ and the \texttt{type} field should contain the value \texttt{'Num}.

More example programs are provided in the \texttt{algeff/test} directory.

\section{The \emph{algeff} syntax}
\begin{grammar}
<ident> ::= "alphanumeric identifier, beginning lowercase"

<op> ::= "alphanumeric identifier, beginning uppercase"

<bool> ::= `true' $\mid$ `false'

<prim> ::= `+' $\mid$ `*' $\mid$ `-'
  \alt `==' $\mid$ `>=' $\mid$ `<='
  \alt `nil' $\mid$ `cons' $\mid$ `nil?' $\mid$ `cons?' $\mid$ `hd' $\mid$ `tl'

<expression> ::= `let' <ident> `=' <expression> `in' <expression>
  \alt `letrec' <ident> <ident> `=' <expression> `in' <expression>
  \alt \{<term>\}$^+$

<term> ::= <ident> $\mid$ <bool> $\mid$ <number>
  \alt <prim> `(' \{ <empty> $\mid$ <expression> \{`,' <expression>\}$^*$ \} `)'
  \alt <lambda> <ident> <expression>
  \alt `if' <expression> `then' <expression> `else' <expression> `end'
  \alt <op> <term>
  \alt `lift' <op> <term>
  \alt `handle' <expression> `with' \{ `|' <handler> \}$^*$ `|' <return> `end'

<handler> ::= <op> <ident> <ident> `->' <expression>

<return> ::= `return' <ident> `->' <expression>
  
\end{grammar}


\printbibliography[heading=bibintoc]

\end{document}

\documentclass[inz, english, shortabstract]{iithesis}
%
\usepackage[utf8]{inputenc}
%
\polishtitle    {Implementacja statycznej i dynamicznej semantyki rachunku z efektami algebraicznymi i ich obsługą z pomocą biblioteki \Redex}
\englishtitle   {Implementation of static and~dynamic semantics for a calculus with algebraic effects and~handlers using \Redex} 
\polishabstract {Abstrakt w języku polskim}
\englishabstract{English abstract}
%
\author         {Maciej Buszka}
%
\advisor        {dr hab. Dariusz Biernacki}
%\date          {}                     % Data złożenia pracy
% Dane do oświadczenia o autorskim wykonaniu
%\transcriptnum {}                     % Numer indeksu
\advisorgen     {dr. hab. Dariusza Biernackiego}
\let\lll\undefined
\usepackage{csquotes, amsmath, amssymb, biblatex, float, ebproof}
%
\usepackage[pdftex]{graphicx}
\addbibresource{mybib.bib}
%
\floatstyle{boxed} 
\restylefloat{figure}
%
\newcommand{\Redex}{\texttt{PLT Redex} }
\newcommand{\Racket}{\texttt{Racket} }
\newcommand{\LC}{\(\lambda\)-calculus }
%
\begin{document}
%
\chapter{Introduction}
% dlaczego:
% experimentation with algebraic effects (calculus with various features)
% 
% lightweight prototyping
%
% goals:
% calculus
% implementation
% automatic testing (failed)
%
%
% What algebraic effects are, why are they interesting, why is it worth to experiment with different approaches/flavors
Algebraic effects \cite{Plotkin2003} are an increasingly popular technique of structuring computational effects.
They allow for seamless composition of multiple effects, while retaining (unlike monads) applicative style of programs.
Coupled with handlers \cite{Plotkin2013} which give programmers ability to interpret effects, they provide a great tool for abstracting over a set of operations which some program may perform and separating this interface from semantics of those operations defined as effect handlers.

% What are other approaches to algebraic effects
As these features are highly desirable many calculi and languages have been developed in order to get them just right; most notable of them being: \emph{Koka}\cite{Leijen2014} (featuring type inference, effect polymorphism with row-types and \emph{Javascript}-like syntax), \emph{Links}\cite{Hillerstrom2016} (featuring \emph{ML}-like syntax, row-typed effect polymorphism and ad-hoc effects) and \emph{Eff}\cite{Bauer2012} with implicit effect checking and recent work on direct compilation to \emph{OCaml}\cite{Kiselyov2018}.
On more theoretical side, various approaches to semantics of algebraic effects can be spotted in literature, both in respect to type system and run-time semantics.
Although most calculi use some form of row-types to implement tracking of effects there are differences in permitted shapes (at most one effect of given type or many effects), whether effects must be defined before use or not and how effects interact with polymorphism and abstraction.
At run-time handlers can wrap the captured continuation (giving so-called deep handlers) or not (shallow handlers) and the very act of finding the right handler can be implemented in various ways, mainly depending on some constructs which skip handlers.

% What am I implementing, what is interesting in this thesis, how it differs from other systems/languages (The main goal of the thesis)
All this variety naturally invites Us to experiment with different features and components of a calculus.
In this thesis I will build such a calculus, describing and justifying my choices and discussing the trade-offs I faced.
In order to to rapidly iterate on design and test the calculus, I decided to use \Redex library which allows for building executable type system judgments and reduction relation.
As such the other goal of my thesis was to assess viability of \Redex for development of bigger calculi.
To briefly summarize my development, the calculus consists of: 
\begin{itemize}
  \item Curry style type system with ad-hoc effects in the style of \emph{Links}, effect rows based on \emph{Koka} and \emph{lift} construct first shown in \cite{Biernacki2017}, implemented as unification based type inference algorithm.
  \item Executable reduction semantics most similar to system of \cite{Biernacki2017}.
  \item CEK style abstract machine with stack and \emph{meta}-stack of handlers
  \item Language front-end which translates human-friendly programs to calculus terms, integrated with \Racket environment, which allows for easy experimentation.
\end{itemize}

% Outline of the thesis
The rest of this thesis is structured as follows: In \autoref{ch:calculus} I describe the calculus in greater detail, in \autoref{ch:implementation} I discuss technicalities of implementation, in \autoref{ch:racket} I summarize the process of integration with \Racket environment and \autoref{ch:manual} is user's manual.
In the reminder of this chapter I introduce main topics of this thesis.

\section{Algebraic effects and handlers}
Algebraic effects and handlers are a language level framework which allow for coherent presentation, abstraction, composition and reasoning about computational effects.
The key idea is to separate invocation of an effectful operation in an expression from the meaning of such operation.
When one invokes an operation, current continuation (up to nearest handler) is captured and passed along with operation's argument to nearest handler.
The handler in turn may execute arbitrary expression, using the continuation once, twice, returning a function which calls the continuation or simply ignoring it.
This way many control structures can be modeled and generalized by algebraic effects and appropriate handlers.
For example, the exceptions can be modeled using a single operation \texttt{Throw} and a handler which either returns the result when computation succeeded or returns default value, ignoring passed continuation.
\begin{verbatim}
handle e with
| Throw () r -> // return default value
| return x   -> x
end
\end{verbatim}
From the language design standpoint algebraic effects provide single implementation of various phenomena which may happen during execution of a program, for example mutable state, I/O, environment lookup, exceptions etc. in a sense that every effect is treated the same, the typing rules are defined for invocation of any operation, and handling of any operation.
Similarly the operational semantics is also quite simple and succinct thanks to uniform treatment of various effects.
This framework is also extendable. With small additions if can handle built-in effects in addition to user-defined ones.

From the language user perspective algebraic effects provide means of abstraction over effects used in a program.
Thanks to easy creation of new effects, one can define special purpose operations and their handlers to better represent domain specific problems while simultaneously using well known effects, defined in standard library.
With effects being tracked by the type system, programmers can enforce purity or specific set of used effects at compile-time, or using effect polymorphism they can write reusable functions which abstract over effects which may happen.
The separation of definition and implementation of effects allows for various interpretations of operations, similar to a technique of \emph{dependency-injection} used for example during testing.
% TODO anonymous vs defined effects, abstract effects, effect polymorphism

\section{Type inference}
Type inference is a technique of algorithmic reconstruction of types for various constructions used in a language.
It allows programmers to write programs with no type annotations, which often feel redundant and obfuscate the meaning of a program.
The most well known type system with inference is a system for \emph{ML} family of languages - \emph{Haskell}, \emph{OCaml}, \emph{SML} which infers the types with no annotations whatsoever.
Formal type system defines grammar of types consisting of base types (\texttt{int}, \texttt{bool} etc.), type constructors (arrows, algebraic data types) and type variables.
The typing rules require types which should be compatible (f.e. formal parameter and argument types) to unify.
The key feature of this system is so called let-polymorphism - generalization of types of let-bound variables.
This way code reuse can be accomplished without complicating the type system and compromising type safety.
The basis of implementation of this system is first order unification algorithm, which syntactically decomposes types and builds a substitution from type variables to types.

\section{Reduction semantics and abstract machines}
% TODO add reference to canonical definitions for good definition of reduction semantics and abstract machines, especially CEK
Reduction semantics is a format for specifying dynamic semantics of a calculus in an operational style.
The basic idea is to first define redexes - expressions which can be reduced, and contexts in which the reduction can happen.
Taking \LC with call-by-value reduction order as an example, the only redex is application of a function to value $ (\lambda x . e) v $.
The possible contexts are: empty context $ \square $ or evaluation of operator part of application $ E e $ or evaluation of operand $ v E $.
\begin{figure}
  \LC language definition  
  \label{fig:lc-lang}
\end{figure}
With these possibilities in mind, we will define binary relation $ \longrightarrow $ which describes single step of reduction.
Such relation can be thought of as a transition system, rewriting terms into simpler ones step by step.
There usually are two approaches to definition of such relation:
\begin{itemize}
  \item Definition of primitive reduction $ (\lambda x . e) v \longrightarrow_p e\{v/x\} $ which operates only on redexes and giving it a closure via following inference rule:
  \begin{prooftree}
    \Hypo{e \longrightarrow_p e'}
    \Infer1{E[e] \longrightarrow E[e']}
  \end{prooftree},
  which says that if we can primitively reduce some expression, than we can do it in any context.
  \item Or definition of $ \longrightarrow $ directly, with decomposition of terms on both sides: $ E[(\lambda x . e) v] \longrightarrow E[e\{v/x\}] $
\end{itemize}
where the syntax $ e\{v/x\} $ means term $ e $ with value $ v $ substituted for variable $ x $, and $ E[e] $ means some context $ E $ with expression $ e $ inserted into the hole.
For both approaches it is important, that any term can be uniquely decomposed into redex and context, because when it is the case, then the relation is deterministic and gives good basis for formulation of abstract machines, interpreters or transformations to some other intermediate representations.
\begin{figure}
  \LC reduction relation
  \label{fig:lc-red}
\end{figure}
\begin{figure}
  \LC reduction example
  \label{fig:lc-red-example}
\end{figure}

Abstract machine is a mathematical construction, usually defined as a set of configurations with deterministic transformations, which are computationally simple.
The goal for formulation of an abstract machine is to mechanize evaluation of terms while retaining semantics given in more abstract format, f.e. reduction semantics, with the correspondence being provable\cite{Felleisen2009}.
As an example I will show a \emph{CEK}-machine for the \LC defined earlier.
The name \emph{CEK} comes from \emph{C}ommand, \emph{E}nvironment and \emph{K}ontinuation.
The machine configuration is a triple $ (e, \rho, \kappa) $ where $ e $ is an expression which is decomposed or reduced, $ \rho $ is an environment mapping variables to values, and the last component $ \kappa $ is a continuation stack, which determines what will happen with value, to which first component eventually reduces.
Thanks to the environment we no longer have to explicitly perform substitution, leading to more machine friendly and efficient implementation.
Given an initial state, the machine can then repeatedly apply transformation relation, either looping, arriving at a final value, or getting stuck. 
\begin{figure}
  \emph{CEK}-machine for \LC
  \label{fig:lc-cek}
\end{figure}

\section{\Redex}
% TODO: Redex section

\chapter{The calculus}\label{ch:calculus}
The calculus implemented in this thesis is based on lambda calculus with call-by-value semantics, similarly to other calculi which allow for computational effects, because fixed evaluation order is essential to obtaining sane program semantics.
Inspired by Links \cite{Hillerstrom2016} the operations are truly ad-hoc meaning that they don't have to be declared before usage.
Moreover the calculus requires no type annotations whatsoever in spirit of \emph{ML} family of languages while still tracking effects which occur in a program.

\section{Abstract syntax}
\begin{figure}
  \centering
  \includegraphics{language}
\end{figure}
Abstract syntax of comprises of forms standard to \LC ($\lambda$ abstractions, variables and applications), extended with number literals and primitive numerical operations (which allow for some example computation), and syntactic forms used by algebraic effects - operation invocations, handle expressions and lift expressions.
Inspired by calculus of Links described in ??? operations are a distinct syntactic category, while lift construct was introduced in Biernacki et. al. % TODO reference

\section{Static semantics}
The type system is based on Koka (Leijen's style of row types) and Links systems (ad-hoc operations).
As the calculus is defined in Curry-style the inference rules describe type reconstruction algorithm.

\subsection{Row types}
Row types as described in \cite{Leijen2005}

\subsection{Type inference}
The main judgment \emph{infer} infers a type and effect row, and calculates new substitution, given typing environment, current substitution and an expression.
As in \emph{ML} languages only simple types can be inferred, along with effect rows 

\subsection{Effect handlers}


\section{Dynamic semantics}

\section{Abstract machine}


\chapter{Implementation}\label{ch:implementation}

\section{\Redex}
% scaling problems

\section{Typing relation}

\section{Unification}

\section{Reduction relation}

\section{Automatic testing}


\chapter{The \Racket environment}\label{ch:racket}

\section{Front-end}

\section{Back-end}

% TODO implementation architecture
\chapter{User's manual}\label{ch:manual}

\printbibliography

%\begin{thebibliography}{1}
%\bibitem{example} \ldots
%\end{thebibliography}

\end{document}
